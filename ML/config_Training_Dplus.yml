input: # files to use
    prompt: ../../AnalysisNonPromptDpp2017/Dplus/MC/LHC18a4a2/Prompt_Dpluspp5TeV_pT_1_50.parquet.gzip
    FD: ../../AnalysisNonPromptDpp2017/Dplus/MC/LHC18a4a2/FD_Dpluspp5TeV_pT_1_50.parquet.gzip
    data: ../../AnalysisNonPromptDpp2017/Dplus/Data/LHC17pq/Data_Dpluspp5TeV_pT_1_50.parquet.gzip

output:
    leg_labels: ['Background', 'Prompt D$^+$', 'Feed-down D$^+$'] # legend labels
    out_labels: ['Bkg', 'Prompt', 'FD'] # output labels
    dir: '../../AnalysisNonPromptDpp2017/Dplus/MLoutput' # output dir

pt_ranges: # ranges in pt to split the data in the ml training and testing
    min: [1, 2, 4, 6, 12] # list
    max: [2, 4, 6, 12, 50] # list

data_prep:
    filt_bkg_mass: inv_mass < 1.82 or 1.92 < inv_mass < 2.00 # pandas query to select bkg candidates
    dataset_opt: equal  # change how the dataset is built, options available: 'equal', 'max_signal'
                        # 'equal' -> same number of prompt/FD/bkg (not using all the signal available)
                        # 'max_signal' -> try to use all the signal (prompt and FD) + add n_bkg = 2 * (n_prompt + n_FD)
    seed_split: 42 # seed used for train_test_split(...)
    test_fraction: 0.5 # fraction of data used for test set and efficiencies     

filtering:
    bkg_mass: inv_mass < 1.82 or 1.92 < inv_mass < 2.00 # pandas query to select bkg candidates

ml:
    training_columns: [d_len, d_len_xy, norm_dl_xy, cos_p, cos_p_xy, imp_par_xy, sig_vert, max_norm_d0d0exp, 
                       nsigComb_Pi_0, nsigComb_K_0, nsigComb_Pi_1, nsigComb_K_1, nsigComb_Pi_2, nsigComb_K_2] 
                       # list of training variables
    plotting_columns: [inv_mass, pt_cand, d_len, d_len_xy, norm_dl_xy, cos_p, cos_p_xy, imp_par_xy, sig_vert, 
                       max_norm_d0d0exp, nsigComb_Pi_0, nsigComb_K_0, nsigComb_Pi_1, nsigComb_K_1, nsigComb_Pi_2, 
                       nsigComb_K_2] # list of variables to plot
    hyper_par: {'max_depth':3, 'learning_rate':0.12, 'n_estimators':250, 'min_child_weight':5, 'colsample':0.9}
