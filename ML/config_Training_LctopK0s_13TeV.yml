input: # files to use, set FD to null for binary classification
    prompt:
        [
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Prompt_filter_pT_2_4.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Prompt_filter_pT_4_6.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Prompt_filter_pT_6_50.root,
        ]
    FD:
        [
            ~/DmesonAnalysis/filterdata/filtered/13TeV/FD_filter_pT_2_4.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/FD_filter_pT_4_6.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/FD_filter_pT_6_50.root,
        ]

    data:
        [
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Data_filter_pT_2_4.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Data_filter_pT_4_6.root,
            ~/DmesonAnalysis/filterdata/filtered/13TeV/Data_filter_pT_6_50.root,
        ]
    treename: treeMLLc

output:
    leg_labels: # legend labels, keep the right number of classes
        Bkg: Background
        Prompt: Prompt $\Lambda_c^+$
        FD: Feed-down $\Lambda_c^+$
    out_labels: # output labels, keep the right number of classes
        Bkg: Bkg
        Prompt: Prompt
        FD: FD
    dir: ~/DmesonAnalysis/ML/trained_models/LctopK0s/13TeV/ # output dir

pt_ranges: # ranges in pt to split the data in the ml training and testing
    min: [2, 4, 6] # list
    max: [4, 6, 50] # list

data_prep:
    filt_bkg_mass: inv_mass < 1.832 or inv_mass > 2.012 # pandas query to select bkg candidates
    dataset_opt:
        "max_signal" # change how the dataset is built, options available: 'equal', 'max_signal'
        # 'equal' -> same number of prompt/FD/bkg (not using all the signal available)
        # 'max_signal' -> try to use all the signal (prompt and FD) + add n_bkg = bkg_mult * (n_prompt + n_FD)
    bkg_mult: [1, 0.3, 0.1, 0.05] # list of multipliers for (nPrompt + nFD) used to determine nCandBkg in the 'max_signal' option
    seed_split: 42 # seed used for train_test_split(...)
    test_fraction: 0.2 # fraction of data used for test set and efficiencies --> set to 1. if you want to apply the model to the full dataframes

ml:
    raw_output: False # use raw_output (True) or probability (False) as output of the model
    roc_auc_average: "macro" # 'macro' or 'weighted'
    roc_auc_approach: "ovo" # 'ovo' or 'ovr'
    training_columns:
        [
            cos_p,
            cos_p_xy,
            d_len,
            d_len_xy,
            norm_dl_xy,
            imp_par_xy,
            pt_prong0,
            nsigComb_Pi_0,
            nsigComb_Pr_0,
            delta_mass_K0s,
            d_len_V0,
            KF_chi2_topo,
            imp_par_prong0,
        ]
        # list of training variables

    hyper_par:
        [
            {
                "max_depth": 4,
                "learning_rate": 0.029,
                "n_estimators": 665,
                "min_child_weight": 2.7,
                "subsample": 0.90,
                "colsample_bytree": 0.97,
                "n_jobs": 4,
                "tree_method": hist,
            },
            {
                "max_depth": 4,
                "learning_rate": 0.092,
                "n_estimators": 674,
                "min_child_weight": 7.0,
                "subsample": 0.90,
                "colsample_bytree": 0.81,
                "n_jobs": 4,
                "tree_method": hist,
            },
            {
                "max_depth": 4,
                "learning_rate": 0.092,
                "n_estimators": 674,
                "min_child_weight": 7.0,
                "subsample": 0.90,
                "colsample_bytree": 0.81,
                "n_jobs": 4,
                "tree_method": hist,
            },
        ]
        # list of dicts of hyperparameters (one for each pT bin)

    hyper_par_opt:
        do_hyp_opt: False # whether to do the parameter optimization
        njobs: 8 # number of parallel jobs used in hyper-parameter optimization, -1. to use all
        nfolds: 5 # number of folds used in cross validation
        initpoints: 10 # steps of random exploration you want to perform
        niter: 15 # steps for bayesian optimization
        bayes_opt_config:
            {
                "max_depth": !!python/tuple [2, 4],
                "learning_rate": !!python/tuple [0.01, 0.1],
                "n_estimators": !!python/tuple [200, 1000],
                "min_child_weight": !!python/tuple [1, 10],
                "subsample": !!python/tuple [0.8, 1.],
                "colsample_bytree": !!python/tuple [0.8, 1.],
            }
            # configuration dictionary for optimize_params_bayes()

    saved_models:
        [
            ~/DmesonAnalysis/ML/trained_models/LctopK0s/ModelHandler_pT_2_4.pickle,
            ~/DmesonAnalysis/ML/trained_models/LctopK0s/ModelHandler_pT_4_8.pickle,
            ~/DmesonAnalysis/ML/trained_models/LctopK0s/ModelHandler_pT_8_50.pickle,
        ]
        # list of saved ModelHandler (path+file), compatible with the pt bins

plots:
    plotting_columns:
        [
            inv_mass,
            pt_cand,
            cos_p,
            cos_p_xy,
            d_len,
            d_len_xy,
            norm_dl_xy,
            imp_par_xy,
            pt_prong0,
            nsigComb_Pi_0,
            nsigComb_Pr_0,
            delta_mass_K0s,
            d_len_V0,
            KF_chi2_topo,
            imp_par_prong0,
        ]
        # list of variables to plot
    train_test_log: True # use log scale for plots of train and test distributions

appl:
    column_to_save_list: ["inv_mass", "pt_cand"] # list of variables saved in the dataframes with the applied models

standalone_appl:
    inputs: [] # list of parquet files for the model application
    output_names: [] # names for the outputs (one for each file)
    output_dir: null # output directory
